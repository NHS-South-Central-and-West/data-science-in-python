{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the use of Polars dataframes as an alternative to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars is a package built in the Rust programming language. It can do much of what can be done with Pandas but with much better performance\n",
    "\n",
    "[Polars documentation](https://docs.pola.rs/)\n",
    "\n",
    "[Comparison with other tools (Polars documentation)](https://docs.pola.rs/user-guide/misc/comparison/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation\n",
    "------------\n",
    "\n",
    "#### With pip\n",
    "\n",
    "`python -m pip install polars`\n",
    "\n",
    "#### With uv\n",
    "\n",
    "`uv add polars`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Polars\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from a .csv\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = './data/simple_monthly_timeseries_data.csv'\n",
    "\n",
    "df_import = pl.read_csv(data, try_parse_dates= True)\n",
    "\n",
    "df_import.glimpse() # get the first 10 entries for each column in the data.\n",
    "\n",
    "# Notice that Polars has parsed the dates for us. The original format of the Month column is dd/mm/yyyy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the dataframe with a \"year\" column and group by year.\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_import.with_columns(          # .with_columns() to add one or more columns\n",
    "    year=pl.col(\"Month\").dt.year(),             # create a \"year\" column by getting the year date part from \"Month\"\n",
    ")\n",
    "# NB: even when you are only adding one column, you end the list of new columns with a comma.\n",
    "\n",
    "df_processed.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (    \n",
    "df_processed.select(                                    # Select the columns you want in the result dataframe\n",
    "    pl.all().exclude(\"Month\"),\n",
    "    )\n",
    "    .group_by(                                          # Group by the specified column\n",
    "    pl.col(\"year\"),\n",
    "    maintain_order= True,                               # This will keep the same order the years appear in the data\n",
    "    )\n",
    "    .agg(                                               # Create an aggregation column\n",
    "    pl.col(\"Activity\").sum().name.prefix(\"total_\"),     # Specify column(s) to aggregate, how to aggregate, and create new name with prefix\n",
    "    )\n",
    ")\n",
    "\n",
    "# .name.prefix is particularly useful when you want to aggregate multiple columns. To do that, it would look like this:\n",
    "# pl.col(\"Activity\",\"Cost\").sum().name.prefix(\"total_\"),\n",
    "# This would result in \"total_Activity\" and \"total_Cost\" columns.\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the \"result\" table to a .csv file\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write_csv('data/result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from a database in conjunction with SQLAlchemy\n",
    "----------------------------------------------------------\n",
    "\n",
    "This is largely the same as the connection we have been using with Pandas; however,\n",
    "the \"read_database\" function uses keyword arguments and the .connect() method needs\n",
    "to be used explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "server = r'BIS-000-SP08.bis.xswhealth.nhs.uk, 14431'\n",
    "database = 'Analyst_SQL_Area'\n",
    "\n",
    "connection_string = ('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+\n",
    "                     ';DATABASE='+database+\n",
    "                     ';ENCRYPT=no;TRUSTED_CONNECTION=yes;'\n",
    "    )\n",
    "\n",
    "connection_url = sa.engine.URL.create(\n",
    "    \"mssql+pyodbc\",\n",
    "    query=dict(odbc_connect=connection_string)\n",
    "    )\n",
    "\n",
    "engine = sa.create_engine(connection_url)\n",
    "\n",
    "query = f'SELECT TOP (1000) * FROM [Analyst_SQL_Area].[Spec].[0002_4-5_CYP_Access_MHB]'\n",
    "\n",
    "df = pl.read_database(query=query, connection=engine.connect())\n",
    "\n",
    "df.glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining tables\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some tables from scratch\n",
    "\n",
    "source_table = pl.DataFrame(\n",
    "    {\n",
    "        \"icb_code\": [\"QRL\",\"QRL\",\"QU9\",\"QU9\"],\n",
    "        \"provider_code\": [\"RHM\",\"RHU\",\"RHW\",\"RNU\"],\n",
    "        \"activity\": [100,200,400,800]\n",
    "    }\n",
    ")\n",
    "\n",
    "icb_lookup = pl.DataFrame(\n",
    "    {\n",
    "        \"icb_code\": [\"QRL\",\"QU9\"],\n",
    "        \"icb_name\": [\"Hampshire and Isle of Wight\", \"Bucks, Oxon and Berks West\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "provider_lookup = pl.DataFrame(\n",
    "    {\n",
    "        \"provider_code\": [\"RHM\",\"RHU\",\"RHW\",\"RNU\"],\n",
    "        \"provider_name\": [\"Southampton General\",\"Portsmouth University Hospital\",\"Royal Berks\",\"Oxford Health\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use method-chaining to join onto both lookup tables.\n",
    "\n",
    "join_result =(\n",
    "    source_table.join(\n",
    "        icb_lookup,\n",
    "        on=\"icb_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        provider_lookup,\n",
    "        on=\"provider_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(join_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating tables\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another table containing additional rows to add onto \"join_result\"\n",
    "\n",
    "rows_to_add = pl.DataFrame(\n",
    "    {\n",
    "        \"icb_code\": [\"QSL\",\"QNQ\",\"QNX\"],\n",
    "        \"provider_code\": [\"RH5\",\"RDU\",\"RX2\"],\n",
    "        \"activity\": [1600,3200,6400],\n",
    "        \"icb_name\": [\"Somerset\",\"Frimley\",\"Sussex\"],\n",
    "        \"provider_name\": [\"Somerset Foundation Trust\",\"Frimley Health\",\"Sussex Partnership\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "concatenation_result = pl.concat(\n",
    "    [\n",
    "        join_result,\n",
    "        rows_to_add,\n",
    "    ],\n",
    "    how=\"vertical\",\n",
    ")\n",
    "\n",
    "print(concatenation_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot / Unpivot\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_result=(\n",
    "    concatenation_result.select(                            # just select part of the concatenation_result\n",
    "        pl.col(\"icb_code\",\"provider_code\",\"activity\"),\n",
    "    )\n",
    "    .pivot(\n",
    "        \"provider_code\",                                    # what we are pivoting\n",
    "        index=\"icb_code\",                                   # the column determining the rows\n",
    "        values=\"activity\",                                  # the values\n",
    "        aggregate_function=\"sum\"                            # pivot operations require an agg. function on the values\n",
    "    )\n",
    ")\n",
    "\n",
    "print(pivot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot the pivot_result\n",
    "\n",
    "unpivot_result = pivot_result.unpivot(\n",
    "    pivot_result.columns[1:],                   # this takes all the provider_code columns without having to name them all\n",
    "    index=\"icb_code\"\n",
    "    )\n",
    "\n",
    "print(unpivot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are at it, let's have a look at how we drop rows containing nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_unpivot_result = unpivot_result.filter(                 # use the .filter() method\n",
    "    pl.col(\"value\").is_not_null()\n",
    ")\n",
    "\n",
    "print(cleaned_unpivot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in visualisations with Altair\n",
    "--------------------------\n",
    "\n",
    "Polars has Altair built in for its chart plotting. Altair has interactive panning and zooming \n",
    "functionality as standard, and it is easy to add tooltips.\n",
    "\n",
    "Lets return to the timeseries data we imported earlier.\n",
    "\n",
    "[Polars visualisation documentation](https://docs.pola.rs/user-guide/misc/visualization/)\n",
    "\n",
    "[Altair documentation](https://altair-viz.github.io/getting_started/overview.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = (\n",
    "    df_import.plot.line(\n",
    "        x=\"Month\",\n",
    "        y=\"Activity\",\n",
    "        tooltip=\"Activity\"\n",
    "    )\n",
    "    .properties(width=500, title=\"Monthly Activty\")\n",
    "    .configure_scale(zero=False)\n",
    ")\n",
    "chart.encoding.x.title = \"Month\"\n",
    "chart.encoding.y.title = \"Activity\"\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "---------\n",
    "\n",
    "For these exercises, we will use this [Water, Sanitation and Hygiene](https://www.kaggle.com/datasets/willianoliveiragibin/water-sanitation-and-hygiene) dataset on Kaggle. \n",
    "\n",
    "It contains data on the proportion of the population with access to safely managed drinking water, by country and year.\n",
    "\n",
    "You would be wise to make use of the Polars documentation, in particular the [Expressions](https://docs.pola.rs/user-guide/expressions/) and [IO](https://docs.pola.rs/user-guide/io/) sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the data from the .csv file into a Polars dataframe and view the first 10 entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/safe_drinking_water.csv'\n",
    "\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the mean values across all years for \"Usage of safely managed drinking water services\" by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a new DataFrame based on the aggregated figures where rows containing \"null\" have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
