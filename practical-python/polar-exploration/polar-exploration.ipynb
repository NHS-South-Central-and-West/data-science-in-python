{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the use of Polars dataframes as an alternative to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars is a package built in the Rust programming language. It can do much of what can be done with Pandas but with much better performance\n",
    "\n",
    "[Polars documentation](https://docs.pola.rs/)\n",
    "\n",
    "[Comparison with other tools (Polars documentation)](https://docs.pola.rs/user-guide/misc/comparison/)\n",
    "\n",
    "#### What advantages do Polars dataframes have over Pandas dataframes?\n",
    "\n",
    "- Much better performance, speed and memory efficiency.\n",
    "    - It is built on an engine written in Rust that is highly optimised for parallel execution and efficient memory usage.\n",
    "    - It builds an execution plan before performing operations (\"lazy execution\").\n",
    "- Native support for a number of operations such as datetime manipulation and rounding floats.\n",
    "- Join operations are faster and deal better with larger datasets.\n",
    "- Better handling of nulls and missing values.\n",
    "- Built-in support for Altair visualisations, which are interactive and have an intuitive syntax.\n",
    "- Ed's personal opinion: \n",
    "    - Polars syntax tends to be more explicit than Pandas in its syntax, which can make it easier to read. That said, it is often possible to perform operations using the same syntax as Pandas, or at least familiar syntax, providing different options.\n",
    "    - Polars displays the data type in more contexts than Pandas -for example, at the top of the columns when you return a dataframe- which serves as a useful reminder when you are considering which operations you need to perform.\n",
    "\n",
    "\n",
    "#### Why might you still opt for Pandas?\n",
    "\n",
    "- Simpler EDA.\n",
    "    - Pandas is a much more mature libary with plenty of exploratory methods, extensions and libraries.\n",
    "    - Simpler syntax.\n",
    "- Seamless integration with a large number of Machine Learning frameworks.\n",
    "    - **That said, this is improving all the time with Polars. `sci-kit learn` supports Polars outputs and Polars integrates seamlessly with TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation\n",
    "------------\n",
    "\n",
    "#### With pip\n",
    "\n",
    "`python -m pip install polars`\n",
    "\n",
    "#### With uv\n",
    "\n",
    "`uv add polars`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Polars\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from a .csv\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 36\n",
      "Columns: 2\n",
      "$ Month    <date> 2019-01-01, 2019-02-01, 2019-03-01, 2019-04-01, 2019-05-01, 2019-06-01, 2019-07-01, 2019-08-01, 2019-09-01, 2019-10-01\n",
      "$ Activity  <i64> 433, 635, 643, 645, 770, 846, 853, 351, 885, 443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = './data/simple_monthly_timeseries_data.csv'\n",
    "\n",
    "df_import = pl.read_csv(data, try_parse_dates= True)\n",
    "\n",
    "df_import.glimpse() # get the first 10 entries for each column in the data.\n",
    "\n",
    "# Notice that Polars has parsed the dates for us. The original format of the Month column is dd/mm/yyyy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the dataframe with a \"year\" column and group by year.\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 36\n",
      "Columns: 3\n",
      "$ Month    <date> 2019-01-01, 2019-02-01, 2019-03-01, 2019-04-01, 2019-05-01, 2019-06-01, 2019-07-01, 2019-08-01, 2019-09-01, 2019-10-01\n",
      "$ Activity  <i64> 433, 635, 643, 645, 770, 846, 853, 351, 885, 443\n",
      "$ year      <i32> 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_processed = df_import.with_columns(          # .with_columns() to add one or more columns\n",
    "    year=pl.col(\"Month\").dt.year(),             # create a \"year\" column by getting the year date part from \"Month\"\n",
    ")\n",
    "# NB: even when you are only adding one column, you end the list of new columns with a comma.\n",
    "\n",
    "df_processed.glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌──────┬────────────────┐\n",
      "│ year ┆ total_Activity │\n",
      "│ ---  ┆ ---            │\n",
      "│ i32  ┆ i64            │\n",
      "╞══════╪════════════════╡\n",
      "│ 2019 ┆ 7881           │\n",
      "│ 2020 ┆ 9852           │\n",
      "│ 2021 ┆ 12314          │\n",
      "└──────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "result = (    \n",
    "df_processed.select(                                    # Select the columns you want in the result dataframe\n",
    "    pl.all().exclude(\"Month\"),\n",
    "    )\n",
    "    .group_by(                                          # Group by the specified column\n",
    "    pl.col(\"year\"),\n",
    "    maintain_order= True,                               # This will keep the same order the years appear in the data\n",
    "    )\n",
    "    .agg(                                               # Create an aggregation column\n",
    "    pl.col(\"Activity\").sum().name.prefix(\"total_\"),     # Specify column(s) to aggregate, how to aggregate, and create new name with prefix\n",
    "    )\n",
    ")\n",
    "\n",
    "# .name.prefix is particularly useful when you want to aggregate multiple columns. To do that, it would look like this:\n",
    "# pl.col(\"Activity\",\"Cost\").sum().name.prefix(\"total_\"),\n",
    "# This would result in \"total_Activity\" and \"total_Cost\" columns.\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the \"result\" table to a .csv file\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write_csv('data/result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from a database in conjunction with SQLAlchemy\n",
    "----------------------------------------------------------\n",
    "\n",
    "This is largely the same as the connection we have been using with Pandas; however,\n",
    "the \"read_database\" function uses keyword arguments and the .connect() method needs\n",
    "to be used explicitly. N.B.: sensitive server/database info has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1000\n",
      "Columns: 9\n",
      "$ Reporting_Period_Start             <datetime[μs]> 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00, 2022-04-01 00:00:00\n",
      "$ Reporting_Period_End               <datetime[μs]> 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00, 2023-03-31 00:00:00\n",
      "$ HI_Breakdown                                <str> 'Total', 'Total', 'Total', 'Total', 'Total', 'Age Group', 'Age Group', 'Age Group', 'Age Group', 'Age Group'\n",
      "$ ICB_Code                                    <str> 'QNQ', 'QNX', 'QRL', 'QSL', 'QU9', 'QNQ', 'QNQ', 'QNQ', 'QNQ', 'QNQ'\n",
      "$ ICB_Name                                    <str> 'NHS FRIMLEY INTEGRATED CARE BOARD', 'NHS SUSSEX INTEGRATED CARE BOARD', 'NHS HAMPSHIRE AND ISLE OF WIGHT INTEGRATED CARE BOARD', 'NHS SOMERSET INTEGRATED CARE BOARD', 'NHS BUCKINGHAMSHIRE, OXFORDSHIRE AND BERKSHIRE WEST INTEGRATED CARE BOARD', 'NHS FRIMLEY INTEGRATED CARE BOARD', 'NHS FRIMLEY INTEGRATED CARE BOARD', 'NHS FRIMLEY INTEGRATED CARE BOARD', 'NHS FRIMLEY INTEGRATED CARE BOARD', 'NHS FRIMLEY INTEGRATED CARE BOARD'\n",
      "$ HI_Category                                 <str> 'NONE', 'NONE', 'NONE', 'NONE', 'NONE', '0 to 5', '11 to 15', '16', '17', '18'\n",
      "$ Mental_Health_Bulletin_Metric_Code          <str> '17a', '17a', '17a', '17a', '17a', '17a', '17a', '17a', '17a', '17a'\n",
      "$ Metric_Name                                 <str> 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact', 'Number of children and young people aged under 18 supported through NHS funded mental health with at least one contact'\n",
      "$ Value                                       <f64> 9105.0, 21210.0, 22295.0, 4595.0, 18365.0, 335.0, 4900.0, 995.0, 855.0, 25.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "server = r'[SERVER NAME HERE]'\n",
    "database = '[DATABASE NAME HERE]'\n",
    "\n",
    "connection_string = ('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+\n",
    "                     ';DATABASE='+database+\n",
    "                     ';ENCRYPT=no;TRUSTED_CONNECTION=yes;'\n",
    "    )\n",
    "\n",
    "connection_url = sa.engine.URL.create(\n",
    "    \"mssql+pyodbc\",\n",
    "    query=dict(odbc_connect=connection_string)\n",
    "    )\n",
    "\n",
    "engine = sa.create_engine(connection_url)\n",
    "\n",
    "query = f'SELECT TOP (1000) * FROM [TABLE NAME HERE]'\n",
    "\n",
    "df = pl.read_database(query=query, connection=engine.connect())\n",
    "\n",
    "df.glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining tables\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 5)\n",
      "┌──────────┬───────────────┬──────────┬─────────────────────────────┬───────────────────────┐\n",
      "│ icb_code ┆ provider_code ┆ activity ┆ icb_name                    ┆ provider_name         │\n",
      "│ ---      ┆ ---           ┆ ---      ┆ ---                         ┆ ---                   │\n",
      "│ str      ┆ str           ┆ i64      ┆ str                         ┆ str                   │\n",
      "╞══════════╪═══════════════╪══════════╪═════════════════════════════╪═══════════════════════╡\n",
      "│ QRL      ┆ RHM           ┆ 100      ┆ Hampshire and Isle of Wight ┆ Southampton General   │\n",
      "│ QRL      ┆ RHU           ┆ 200      ┆ Hampshire and Isle of Wight ┆ Portsmouth University │\n",
      "│          ┆               ┆          ┆                             ┆ Hospital              │\n",
      "│ QU9      ┆ RHW           ┆ 400      ┆ Bucks, Oxon and Berks West  ┆ Royal Berks           │\n",
      "│ QU9      ┆ RNU           ┆ 800      ┆ Bucks, Oxon and Berks West  ┆ Oxford Health         │\n",
      "└──────────┴───────────────┴──────────┴─────────────────────────────┴───────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create some tables from scratch\n",
    "\n",
    "source_table = pl.DataFrame(\n",
    "    {\n",
    "        \"icb_code\": [\"QRL\",\"QRL\",\"QU9\",\"QU9\"],\n",
    "        \"provider_code\": [\"RHM\",\"RHU\",\"RHW\",\"RNU\"],\n",
    "        \"activity\": [100,200,400,800]\n",
    "    }\n",
    ")\n",
    "\n",
    "icb_lookup = pl.DataFrame(\n",
    "    {\n",
    "        \"icb_code\": [\"QRL\",\"QU9\"],\n",
    "        \"icb_name\": [\"Hampshire and Isle of Wight\", \"Bucks, Oxon and Berks West\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "provider_lookup = pl.DataFrame(\n",
    "    {\n",
    "        \"provider_code\": [\"RHM\",\"RHU\",\"RHW\",\"RNU\"],\n",
    "        \"provider_name\": [\"Southampton General\",\"Portsmouth University Hospital\",\"Royal Berks\",\"Oxford Health\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use method-chaining to join onto both lookup tables.\n",
    "\n",
    "join_result =(\n",
    "    source_table.join(\n",
    "        icb_lookup,\n",
    "        on=\"icb_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        provider_lookup,\n",
    "        on=\"provider_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(join_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating tables\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 5)\n",
      "┌──────────┬───────────────┬──────────┬─────────────────────────────┬───────────────────────────┐\n",
      "│ icb_code ┆ provider_code ┆ activity ┆ icb_name                    ┆ provider_name             │\n",
      "│ ---      ┆ ---           ┆ ---      ┆ ---                         ┆ ---                       │\n",
      "│ str      ┆ str           ┆ i64      ┆ str                         ┆ str                       │\n",
      "╞══════════╪═══════════════╪══════════╪═════════════════════════════╪═══════════════════════════╡\n",
      "│ QRL      ┆ RHM           ┆ 100      ┆ Hampshire and Isle of Wight ┆ Southampton General       │\n",
      "│ QRL      ┆ RHU           ┆ 200      ┆ Hampshire and Isle of Wight ┆ Portsmouth University     │\n",
      "│          ┆               ┆          ┆                             ┆ Hospital                  │\n",
      "│ QU9      ┆ RHW           ┆ 400      ┆ Bucks, Oxon and Berks West  ┆ Royal Berks               │\n",
      "│ QU9      ┆ RNU           ┆ 800      ┆ Bucks, Oxon and Berks West  ┆ Oxford Health             │\n",
      "│ QSL      ┆ RH5           ┆ 1600     ┆ Somerset                    ┆ Somerset Foundation Trust │\n",
      "│ QNQ      ┆ RDU           ┆ 3200     ┆ Frimley                     ┆ Frimley Health            │\n",
      "│ QNX      ┆ RX2           ┆ 6400     ┆ Sussex                      ┆ Sussex Partnership        │\n",
      "└──────────┴───────────────┴──────────┴─────────────────────────────┴───────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Create another table containing additional rows to add onto \"join_result\"\n",
    "\n",
    "rows_to_add = pl.DataFrame(\n",
    "    {\n",
    "        \"icb_code\": [\"QSL\",\"QNQ\",\"QNX\"],\n",
    "        \"provider_code\": [\"RH5\",\"RDU\",\"RX2\"],\n",
    "        \"activity\": [1600,3200,6400],\n",
    "        \"icb_name\": [\"Somerset\",\"Frimley\",\"Sussex\"],\n",
    "        \"provider_name\": [\"Somerset Foundation Trust\",\"Frimley Health\",\"Sussex Partnership\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "concatenation_result = pl.concat(\n",
    "    [\n",
    "        join_result,\n",
    "        rows_to_add,\n",
    "    ],\n",
    "    how=\"vertical\",\n",
    ")\n",
    "\n",
    "print(concatenation_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot / Unpivot\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 8)\n",
      "┌──────────┬──────┬──────┬──────┬──────┬──────┬──────┬──────┐\n",
      "│ icb_code ┆ RHM  ┆ RHU  ┆ RHW  ┆ RNU  ┆ RH5  ┆ RDU  ┆ RX2  │\n",
      "│ ---      ┆ ---  ┆ ---  ┆ ---  ┆ ---  ┆ ---  ┆ ---  ┆ ---  │\n",
      "│ str      ┆ i64  ┆ i64  ┆ i64  ┆ i64  ┆ i64  ┆ i64  ┆ i64  │\n",
      "╞══════════╪══════╪══════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│ QRL      ┆ 100  ┆ 200  ┆ null ┆ null ┆ null ┆ null ┆ null │\n",
      "│ QU9      ┆ null ┆ null ┆ 400  ┆ 800  ┆ null ┆ null ┆ null │\n",
      "│ QSL      ┆ null ┆ null ┆ null ┆ null ┆ 1600 ┆ null ┆ null │\n",
      "│ QNQ      ┆ null ┆ null ┆ null ┆ null ┆ null ┆ 3200 ┆ null │\n",
      "│ QNX      ┆ null ┆ null ┆ null ┆ null ┆ null ┆ null ┆ 6400 │\n",
      "└──────────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "pivot_result=(\n",
    "    concatenation_result.select(                            # just select part of the concatenation_result\n",
    "        pl.col(\"icb_code\",\"provider_code\",\"activity\"),\n",
    "    )\n",
    "    .pivot(\n",
    "        \"provider_code\",                                    # what we are pivoting\n",
    "        index=\"icb_code\",                                   # the column determining the rows\n",
    "        values=\"activity\",                                  # the values\n",
    "        aggregate_function=\"sum\"                            # pivot operations require an agg. function on the values\n",
    "    )\n",
    ")\n",
    "\n",
    "print(pivot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (35, 3)\n",
      "┌──────────┬──────────┬───────┐\n",
      "│ icb_code ┆ variable ┆ value │\n",
      "│ ---      ┆ ---      ┆ ---   │\n",
      "│ str      ┆ str      ┆ i64   │\n",
      "╞══════════╪══════════╪═══════╡\n",
      "│ QRL      ┆ RHM      ┆ 100   │\n",
      "│ QU9      ┆ RHM      ┆ null  │\n",
      "│ QSL      ┆ RHM      ┆ null  │\n",
      "│ QNQ      ┆ RHM      ┆ null  │\n",
      "│ QNX      ┆ RHM      ┆ null  │\n",
      "│ …        ┆ …        ┆ …     │\n",
      "│ QRL      ┆ RX2      ┆ null  │\n",
      "│ QU9      ┆ RX2      ┆ null  │\n",
      "│ QSL      ┆ RX2      ┆ null  │\n",
      "│ QNQ      ┆ RX2      ┆ null  │\n",
      "│ QNX      ┆ RX2      ┆ 6400  │\n",
      "└──────────┴──────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Unpivot the pivot_result\n",
    "\n",
    "unpivot_result = pivot_result.unpivot(\n",
    "    pivot_result.columns[1:],                   # this takes all the provider_code columns without having to name them all\n",
    "    index=\"icb_code\"\n",
    "    )\n",
    "\n",
    "print(unpivot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are at it, let's have a look at how we drop rows containing nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 3)\n",
      "┌──────────┬──────────┬───────┐\n",
      "│ icb_code ┆ variable ┆ value │\n",
      "│ ---      ┆ ---      ┆ ---   │\n",
      "│ str      ┆ str      ┆ i64   │\n",
      "╞══════════╪══════════╪═══════╡\n",
      "│ QRL      ┆ RHM      ┆ 100   │\n",
      "│ QRL      ┆ RHU      ┆ 200   │\n",
      "│ QU9      ┆ RHW      ┆ 400   │\n",
      "│ QU9      ┆ RNU      ┆ 800   │\n",
      "│ QSL      ┆ RH5      ┆ 1600  │\n",
      "│ QNQ      ┆ RDU      ┆ 3200  │\n",
      "│ QNX      ┆ RX2      ┆ 6400  │\n",
      "└──────────┴──────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "cleaned_unpivot_result = unpivot_result.filter(                 # use the .filter() method\n",
    "    pl.col(\"value\").is_not_null()\n",
    ")\n",
    "\n",
    "print(cleaned_unpivot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in visualisations with Altair\n",
    "--------------------------\n",
    "\n",
    "Polars has Altair built in for its chart plotting. Altair has interactive panning and zooming \n",
    "functionality as standard, and it is easy to add tooltips.\n",
    "\n",
    "Lets return to the timeseries data we imported earlier.\n",
    "\n",
    "[Polars visualisation documentation](https://docs.pola.rs/user-guide/misc/visualization/)\n",
    "\n",
    "[Altair documentation](https://altair-viz.github.io/getting_started/overview.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3adfcf09cf1b4fde8046d9eed4777192.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3adfcf09cf1b4fde8046d9eed4777192.vega-embed details,\n",
       "  #altair-viz-3adfcf09cf1b4fde8046d9eed4777192.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3adfcf09cf1b4fde8046d9eed4777192\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3adfcf09cf1b4fde8046d9eed4777192\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3adfcf09cf1b4fde8046d9eed4777192\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"scale\": {\"zero\": false}}, \"data\": {\"name\": \"data-02e30ed1cd2cc191f912ba3b8cad3250\"}, \"mark\": {\"type\": \"line\", \"tooltip\": true}, \"encoding\": {\"tooltip\": {\"field\": \"Activity\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"Month\", \"title\": \"Month\", \"type\": \"temporal\"}, \"y\": {\"field\": \"Activity\", \"title\": \"Activity\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Monthly Activty\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-02e30ed1cd2cc191f912ba3b8cad3250\": [{\"Month\": \"2019-01-01T00:00:00\", \"Activity\": 433}, {\"Month\": \"2019-02-01T00:00:00\", \"Activity\": 635}, {\"Month\": \"2019-03-01T00:00:00\", \"Activity\": 643}, {\"Month\": \"2019-04-01T00:00:00\", \"Activity\": 645}, {\"Month\": \"2019-05-01T00:00:00\", \"Activity\": 770}, {\"Month\": \"2019-06-01T00:00:00\", \"Activity\": 846}, {\"Month\": \"2019-07-01T00:00:00\", \"Activity\": 853}, {\"Month\": \"2019-08-01T00:00:00\", \"Activity\": 351}, {\"Month\": \"2019-09-01T00:00:00\", \"Activity\": 885}, {\"Month\": \"2019-10-01T00:00:00\", \"Activity\": 443}, {\"Month\": \"2019-11-01T00:00:00\", \"Activity\": 612}, {\"Month\": \"2019-12-01T00:00:00\", \"Activity\": 765}, {\"Month\": \"2020-01-01T00:00:00\", \"Activity\": 541}, {\"Month\": \"2020-02-01T00:00:00\", \"Activity\": 794}, {\"Month\": \"2020-03-01T00:00:00\", \"Activity\": 804}, {\"Month\": \"2020-04-01T00:00:00\", \"Activity\": 806}, {\"Month\": \"2020-05-01T00:00:00\", \"Activity\": 963}, {\"Month\": \"2020-06-01T00:00:00\", \"Activity\": 1058}, {\"Month\": \"2020-07-01T00:00:00\", \"Activity\": 1066}, {\"Month\": \"2020-08-01T00:00:00\", \"Activity\": 439}, {\"Month\": \"2020-09-01T00:00:00\", \"Activity\": 1106}, {\"Month\": \"2020-10-01T00:00:00\", \"Activity\": 554}, {\"Month\": \"2020-11-01T00:00:00\", \"Activity\": 765}, {\"Month\": \"2020-12-01T00:00:00\", \"Activity\": 956}, {\"Month\": \"2021-01-01T00:00:00\", \"Activity\": 677}, {\"Month\": \"2021-02-01T00:00:00\", \"Activity\": 992}, {\"Month\": \"2021-03-01T00:00:00\", \"Activity\": 1005}, {\"Month\": \"2021-04-01T00:00:00\", \"Activity\": 1008}, {\"Month\": \"2021-05-01T00:00:00\", \"Activity\": 1203}, {\"Month\": \"2021-06-01T00:00:00\", \"Activity\": 1322}, {\"Month\": \"2021-07-01T00:00:00\", \"Activity\": 1333}, {\"Month\": \"2021-08-01T00:00:00\", \"Activity\": 548}, {\"Month\": \"2021-09-01T00:00:00\", \"Activity\": 1383}, {\"Month\": \"2021-10-01T00:00:00\", \"Activity\": 692}, {\"Month\": \"2021-11-01T00:00:00\", \"Activity\": 956}, {\"Month\": \"2021-12-01T00:00:00\", \"Activity\": 1195}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = (\n",
    "    df_import.plot.line(\n",
    "        x=\"Month\",\n",
    "        y=\"Activity\",\n",
    "        tooltip=\"Activity\"\n",
    "    )\n",
    "    .properties(width=500, title=\"Monthly Activty\")\n",
    "    .configure_scale(zero=False)\n",
    ")\n",
    "chart.encoding.x.title = \"Month\"\n",
    "chart.encoding.y.title = \"Activity\"\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "---------\n",
    "\n",
    "For these exercises, we will use this [Water, Sanitation and Hygiene](https://www.kaggle.com/datasets/willianoliveiragibin/water-sanitation-and-hygiene) dataset on Kaggle. \n",
    "\n",
    "It contains data on the proportion of the population with access to safely managed drinking water, by country and year.\n",
    "\n",
    "You would be wise to make use of the Polars documentation, in particular the [Expressions](https://docs.pola.rs/user-guide/expressions/) and [IO](https://docs.pola.rs/user-guide/io/) sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the data from the .csv file into a Polars dataframe and view the first 10 entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 5737\n",
      "Columns: 3\n",
      "$ Country                                         <str> 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan'\n",
      "$ Year                                            <i64> 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009\n",
      "$ Usage of safely managed drinking water services <f64> 11.093327, 11.105221, 12.007733, 12.909922, 13.818684, 14.733853, 15.648427, 16.562523, 17.476011, 18.388884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = 'data/safe_drinking_water.csv'\n",
    "\n",
    "# your code here...\n",
    "\n",
    "df_import = pl.read_csv(file)\n",
    "\n",
    "df_import.glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the mean values across all years for \"Usage of safely managed drinking water services\" by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (254, 2)\n",
      "┌───────────────────────┬─────────────────────────────────┐\n",
      "│ Country               ┆ avg_Usage of safely managed dr… │\n",
      "│ ---                   ┆ ---                             │\n",
      "│ str                   ┆ f64                             │\n",
      "╞═══════════════════════╪═════════════════════════════════╡\n",
      "│ Afghanistan           ┆ 20.237917                       │\n",
      "│ Africa (WHO)          ┆ 25.927864                       │\n",
      "│ Albania               ┆ 62.007785                       │\n",
      "│ Algeria               ┆ 73.702565                       │\n",
      "│ American Samoa        ┆ 87.329029                       │\n",
      "│ …                     ┆ …                               │\n",
      "│ Western Pacific (WHO) ┆ null                            │\n",
      "│ World                 ┆ 66.808092                       │\n",
      "│ Yemen                 ┆ null                            │\n",
      "│ Zambia                ┆ null                            │\n",
      "│ Zimbabwe              ┆ 28.01352                        │\n",
      "└───────────────────────┴─────────────────────────────────┘\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nBonus material to get columns for multiple aggregations:\\n\\n.agg([\\n        pl.col(\"Usage of safely managed drinking water services\").mean().alias(\"avg_Usage\"),\\n        pl.col(\"Usage of safely managed drinking water services\").min().alias(\"min_Usage\"),\\n        pl.col(\"Usage of safely managed drinking water services\").max().alias(\"max_Usage\")\\n    ])\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here...\n",
    "\n",
    "df_aggregated = (\n",
    "    df_import.select(\n",
    "        pl.all().exclude(\"Year\"),\n",
    "    )\n",
    "    .group_by(\n",
    "    pl.col(\"Country\"),\n",
    "    maintain_order= True,\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"Usage of safely managed drinking water services\").mean().name.prefix(\"avg_\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(df_aggregated)\n",
    "\n",
    "\"\"\"\n",
    "Bonus material to get columns for multiple aggregations:\n",
    "\n",
    ".agg([\n",
    "        pl.col(\"Usage of safely managed drinking water services\").mean().alias(\"avg_Usage\"),\n",
    "        pl.col(\"Usage of safely managed drinking water services\").min().alias(\"min_Usage\"),\n",
    "        pl.col(\"Usage of safely managed drinking water services\").max().alias(\"max_Usage\")\n",
    "    ])\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a new DataFrame based on the aggregated figures where rows containing \"null\" have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (169, 2)\n",
      "┌───────────────────┬─────────────────────────────────┐\n",
      "│ Country           ┆ avg_Usage of safely managed dr… │\n",
      "│ ---               ┆ ---                             │\n",
      "│ str               ┆ f64                             │\n",
      "╞═══════════════════╪═════════════════════════════════╡\n",
      "│ Afghanistan       ┆ 20.237917                       │\n",
      "│ Africa (WHO)      ┆ 25.927864                       │\n",
      "│ Albania           ┆ 62.007785                       │\n",
      "│ Algeria           ┆ 73.702565                       │\n",
      "│ American Samoa    ┆ 87.329029                       │\n",
      "│ …                 ┆ …                               │\n",
      "│ Uzbekistan        ┆ 67.485789                       │\n",
      "│ Vietnam           ┆ 51.779854                       │\n",
      "│ Wallis and Futuna ┆ 69.01344                        │\n",
      "│ World             ┆ 66.808092                       │\n",
      "│ Zimbabwe          ┆ 28.01352                        │\n",
      "└───────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# your code here...\n",
    "\n",
    "cleaned_df_aggregated = df_aggregated.filter(\n",
    "    df_aggregated[\"avg_Usage of safely managed drinking water services\"].is_not_null()\n",
    ")\n",
    "\n",
    "print(cleaned_df_aggregated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
